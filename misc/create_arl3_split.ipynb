{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create split.txt files for ARL Protocol 3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import os.path as osp\n",
    "import random\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../../dataset/odin_data/'\n",
    "\n",
    "src = 'VIS_align'\n",
    "dest = 'splits'\n",
    "# splits = [0,1,2,3,4]\n",
    "splits = [5,6,7]\n",
    "\n",
    "num_train = 71\n",
    "num_val = 25\n",
    "num_test = 25\n",
    "\n",
    "src_path = os.path.join(root, src)\n",
    "dest_path = os.path.join(root, dest)\n",
    "split_dir = dest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(x):\n",
    "    return x.split('_')[2][:-1]\n",
    "\n",
    "def get_full_id(x):\n",
    "    return x.split('_')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total len: 5419\n",
      "Unique persons: 121\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(src_path)\n",
    "ids = list(set(([get_id(x) for x in files])))\n",
    "\n",
    "print('Total len:', len(files))\n",
    "print('Unique persons:', len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train len: 71\n",
      "Val len: 25\n",
      "Test len: 25\n",
      "Train ids saved to ../../dataset/odin_data/splits/train_5.txt\n",
      "Val ids saved to ../../dataset/odin_data/splits/val_5.txt\n",
      "Test ids saved to ../../dataset/odin_data/splits/test_5.txt\n",
      "Train len: 71\n",
      "Val len: 25\n",
      "Test len: 25\n",
      "Train ids saved to ../../dataset/odin_data/splits/train_6.txt\n",
      "Val ids saved to ../../dataset/odin_data/splits/val_6.txt\n",
      "Test ids saved to ../../dataset/odin_data/splits/test_6.txt\n",
      "Train len: 71\n",
      "Val len: 25\n",
      "Test len: 25\n",
      "Train ids saved to ../../dataset/odin_data/splits/train_7.txt\n",
      "Val ids saved to ../../dataset/odin_data/splits/val_7.txt\n",
      "Test ids saved to ../../dataset/odin_data/splits/test_7.txt\n"
     ]
    }
   ],
   "source": [
    "break\n",
    "np.random.seed(0)\n",
    "os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "# Saving only ids in split files\n",
    "for split in splits:\n",
    "    train_set = np.random.choice(ids, size=num_train, replace=False)\n",
    "    rem_set = set(ids) - set(train_set)\n",
    "    val_set = np.random.choice(list(rem_set), size=num_val, replace=False)\n",
    "    test_set = list(rem_set - set(val_set))\n",
    "\n",
    "    assert(len(set(test_set).intersection(set(train_set))) == 0)\n",
    "    assert(len(set(val_set).intersection(set(train_set))) == 0)\n",
    "\n",
    "    train_ids = [x + '\\n' for x in train_set]\n",
    "    val_ids = [x + '\\n' for x in val_set]\n",
    "    test_ids = [x + '\\n' for x in test_set]\n",
    "\n",
    "    print('Train len:', len(train_ids))\n",
    "    print('Val len:', len(val_ids))\n",
    "    print('Test len:', len(test_ids))\n",
    "    \n",
    "    train_path = os.path.join(dest_path, 'train_{}.txt'.format(split))\n",
    "    val_path = os.path.join(dest_path, 'val_{}.txt'.format(split))\n",
    "    test_path = os.path.join(dest_path, 'test_{}.txt'.format(split))\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.writelines(train_ids)\n",
    "    print('Train ids saved to', train_path)\n",
    "    \n",
    "    with open(val_path, 'w') as f:\n",
    "        f.writelines(val_ids)\n",
    "    print('Val ids saved to', val_path)\n",
    "    \n",
    "    with open(test_path, 'w') as f:\n",
    "        f.writelines(test_ids)\n",
    "    print('Test ids saved to', test_path)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Gallery and probe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variation(x):\n",
    "    x = x.split('_')[-3]\n",
    "    return x\n",
    "\n",
    "# unique variations for gallery. glasses and no glasses\n",
    "# variations = ['0_b_', '1_b_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 5\n",
      "Number of test images: 1108\n",
      "Number of test ids: 31\n",
      "Num gallery: 31\n",
      "Num probe: 1077\n",
      "Split 6\n",
      "Number of test images: 1172\n",
      "Number of test ids: 31\n",
      "Num gallery: 31\n",
      "Num probe: 1141\n",
      "Split 7\n",
      "Number of test images: 1196\n",
      "Number of test ids: 29\n",
      "Num gallery: 29\n",
      "Num probe: 1167\n"
     ]
    }
   ],
   "source": [
    "for split in splits:\n",
    "    print('Split', split)\n",
    "    test_path = os.path.join(split_dir, 'test_{}.txt'.format(split))\n",
    "    gallery_file = osp.join(split_dir, 'gallery_{}.txt'.format(split))\n",
    "    probe_file = osp.join(split_dir, 'probe_{}.txt'.format(split))\n",
    "    \n",
    "    test_ids = open(test_path, 'r').read().split('\\n')[:-1]\n",
    "    test_files = [x for x in files if get_id(x) in test_ids]\n",
    "    \n",
    "    # Treat glasses and no glasses as separate ids\n",
    "    test_dic = {}\n",
    "    for x in test_files:\n",
    "        if get_full_id(x) not in test_dic:\n",
    "            test_dic[get_full_id(x)] = []\n",
    "        test_dic[get_full_id(x)].append(x)\n",
    "    \n",
    "    print('Number of test images:', len(test_files))\n",
    "    print('Number of test ids:', len(test_dic.keys()))\n",
    "    \n",
    "    g_files = []\n",
    "    for id_ in test_dic.keys():\n",
    "        # randomly sample a baseline image for each identity for forming gallery set\n",
    "        cnt = 0\n",
    "        \n",
    "        var_files = [x for x in test_dic[id_] if variation(x) == 'b']\n",
    "        if len(var_files):\n",
    "            g_files += random.sample(var_files, 1)\n",
    "            cnt += 1\n",
    "\n",
    "        if cnt == 0:\n",
    "            # Add a random expression image if no neutral image\n",
    "            var_files = [x for x in test_dic[id_] if variation(x) == 'e']\n",
    "            if len(var_files):\n",
    "                g_files += random.sample(var_files, 1)\n",
    "                cnt += 1\n",
    "        \n",
    "        if cnt == 0:\n",
    "            # Add a random pose image\n",
    "            var_files = [x for x in test_dic[id_] if variation(x) == 'p']\n",
    "            g_files += random.sample(var_files, 1)\n",
    "            cnt += 1\n",
    "        \n",
    "            \n",
    "    p_files = list(set(test_files) - set(g_files))\n",
    "    \n",
    "    print('Num gallery:', len(g_files))\n",
    "    print('Num probe:', len(p_files))\n",
    "    \n",
    "    random.shuffle(g_files)\n",
    "    random.shuffle(p_files)\n",
    "    g_files = [x + '\\n' for x in g_files]\n",
    "    p_files = [x + '\\n' for x in p_files]\n",
    "    \n",
    "    with open(gallery_file, 'w') as f:\n",
    "        f.writelines(g_files)\n",
    "        \n",
    "    with open(probe_file, 'w') as f:\n",
    "        f.writelines(p_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 5\n",
      "Phase: train, Glasses files: 516, Total files: 3300\n",
      "Phase: val, Glasses files: 78, Total files: 1011\n",
      "Phase: test, Glasses files: 244, Total files: 1108\n",
      "Split 6\n",
      "Phase: train, Glasses files: 440, Total files: 3165\n",
      "Phase: val, Glasses files: 182, Total files: 1082\n",
      "Phase: test, Glasses files: 216, Total files: 1172\n",
      "Split 7\n",
      "Phase: train, Glasses files: 606, Total files: 3425\n",
      "Phase: val, Glasses files: 111, Total files: 798\n",
      "Phase: test, Glasses files: 121, Total files: 1196\n"
     ]
    }
   ],
   "source": [
    "A_mode = \"Polar\"\n",
    "def remove_pose(A_paths):\n",
    "    A_paths = [x for x in A_paths if '_p_' not in x]\n",
    "    print('Removed pose images')\n",
    "    return A_paths\n",
    "\n",
    "def make_files(phase, split):\n",
    "    dir_A = src_path\n",
    "\n",
    "    split_file = os.path.join(split_dir, '{}_{}.txt'.format(phase, split))\n",
    "    ids = open(split_file, 'r').read().split('\\n')[:-1]\n",
    "\n",
    "    A_paths = glob.glob(os.path.join(dir_A, '*.[pj][np]g'), recursive=True)\n",
    "    A_ext = os.path.splitext(A_paths[0])[-1]\n",
    "    \n",
    "    A_ids = [os.path.splitext(os.path.basename(x))[0] for x in A_paths]\n",
    "    \n",
    "    # retain only train/test files\n",
    "    A_ids = set(x.replace(A_mode, 'XX') for x in A_ids if get_id(x) in ids)\n",
    "    \n",
    "    A_paths = [x.replace('XX', A_mode) + A_ext for x in A_ids]\n",
    "    \n",
    "    spects_cnt = 0\n",
    "    for p in A_paths:\n",
    "        if get_full_id(p)[-1] != '0':\n",
    "            spects_cnt += 1\n",
    "            \n",
    "    print(\"Phase: {}, Glasses files: {}, Total files: {}\".format(phase, spects_cnt, len(A_paths)))\n",
    "    \n",
    "for split in splits:\n",
    "    print('Split', split)\n",
    "    make_files('train', split)\n",
    "    make_files('val', split)\n",
    "    make_files('test', split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
